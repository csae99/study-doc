Workflow 1: Docker-based Deployment

 Steps:

1.  Code in Git Repository
       Developer writes application code and pushes it to GitHub/GitLab/Bitbucket.

2.  Dockerfile
       A text file that defines how to build the application into a Docker image (includes OS, dependencies, app code).

3.  Build Docker Image
       Using `docker build`, the application is packaged into an image.

4.  Push to Docker Registry
       Image is stored in a registry like:
           Docker Hub
           AWS ECR
           Azure ACR
           GCP Artifact Registry

5.  Deploy with Docker Compose
       A `docker-compose.yml` file defines how multiple containers run together (e.g., app + database).
       Runs on a VM or server using `docker-compose up`.

6.  Networking & Routing
       Expose app via Load Balancer or Reverse Proxy (e.g., Nginx).
       DNS services like Route53, Cloudflare, or GoDaddy map domain names to server IP.



 Visual Representation (Docker Workflow)

    Git Repo → Dockerfile → Docker Image → Docker Registry → Docker Compose → Load Balancer → DNS
	
Lets take a small example for docker:

hello-app/
├─ src/
│  └─ server.js          # minimal app
├─ package.json
├─ Dockerfile
└─ docker-compose.yml
-----
Dockerfile:


# Use small official Node runtime
FROM node:18-alpine

# Set working directory inside the container
WORKDIR /app

# Install only production deps using lockfile if present
COPY package.json package-lock.json* ./
RUN npm ci --only=production

# Copy application source
COPY src ./src

# App config
ENV NODE_ENV=production
ENV PORT=3000
EXPOSE 3000

# Run the app
CMD ["node", "src/server.js"]
-----

# Docker build cmds:


docker build -t hello-app:1.0.0 .
docker run -p 8080:3000 hello-app:1.0.0
# visit http://localhost:8080

# Push dockerimage to Dockerhub cmds:
docker login
docker tag hello-app:1.0.0 <dockerhubUser>/hello-app:1.0.0
docker push <dockerhubUser>/hello-app:1.0.0

# Push dockerimage to ECR cmds:

aws ecr create-repository --repository-name hello-app
aws ecr get-login-password --region <region> \
  | docker login --username AWS --password-stdin <account>.dkr.ecr.<region>.amazonaws.com

docker tag hello-app:1.0.0 <account>.dkr.ecr.<region>.amazonaws.com/hello-app:1.0.0
docker push <account>.dkr.ecr.<region>.amazonaws.com/hello-app:1.0.0

# Push dockerimage to ACR cmds:
az acr create -n <acrName> -g <resourceGroup> --sku Basic
az acr login -n <acrName>

docker tag hello-app:1.0.0 <acrName>.azurecr.io/hello-app:1.0.0
docker push <acrName>.azurecr.io/hello-app:1.0.0

-----
# docker-compose.yml


version: "3.8"

services:
  web:
    # Option 1: build from local Dockerfile
    # build: .

    # Option 2: pull from registry (recommended for prod)
    image: <REGISTRY>/<REPO>/hello-app:1.0.0
    ports:
      - "80:3000"     # expose on host port 80
    environment:
      NODE_ENV: production
      PORT: "3000"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3000/healthz"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s

    # If private registry, provide pull credentials using 'docker login' on the host
------

# Cmds to run docker-compose.yml :

docker compose up -d

# Routing & DNS (Compose)

If your server has a public IP, you can map port 80 directly and point DNS to it.
Create an A record (or CNAME) for your domain:

Route 53: Hosted zone → “Create record” → A/ALIAS → target = your server IP or LB DNS.
Cloudflare: DNS → Add record → Type A → Name app → IPv4 address = server IP. (Proxy on/off as needed)
GoDaddy: DNS Management → Add → A record → Host app → Points to your server IP.


# So here's what happening :

Docker (single host)
Git → Dockerfile → Image → Registry → docker-compose up → (optional reverse proxy) → DNS → Users

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Workflow 2: Kubernetes-based Deployment

 Steps:

1.  Code in Git Repository
       Same as before.

2.  Dockerfile & Image
       Build and push image to registry (ECR, ACR, etc.).

3.  Kubernetes Manifests
       YAML files define:
           Deployment (how many pods)
           Service (internal/external access)
           Ingress (routes traffic to services)

4.  Apply Manifests
       Use `kubectl apply -f` to deploy on a Kubernetes cluster (EKS, AKS, GKE, or on-prem).

5.  Ingress Controller
       Handles routing (e.g., Nginx Ingress, Traefik).
       Connects to Load Balancer (AWS ALB, Azure LB).

6.  DNS
       Domain name points to Load Balancer via Route53, Cloudflare, or GoDaddy.



 Visual Representation (Kubernetes Workflow)

    Git Repo → Dockerfile → Docker Image → Docker Registry → K8s Manifests → K8s Cluster → Ingress → Load Balancer → DNS



   Key Differences

   Docker Compose: Good for small setups, single server.
   Kubernetes: Scalable, distributed, production-grade.



Lets take a small example for k8s:

# Project Structure:

hello-app/
├─ src/
│  └─ server.js          # minimal app
├─ package.json
└─ k8s/
   ├─ deployment.yaml
   ├─ service.yaml
   └─ ingress.yaml
   
# You can utlize the Docker build and docker Push steps from the above example :

----
k8s/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-app
  labels:
    app: hello-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hello-app
  template:
    metadata:
      labels:
        app: hello-app
    spec:
      containers:
        - name: web
          image: <REGISTRY>/<REPO>/hello-app:1.0.0
          ports:
            - containerPort: 3000
          env:
            - name: NODE_ENV
              value: "production"
            - name: PORT
              value: "3000"
          readinessProbe:
            httpGet:
              path: /healthz
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /healthz
              port: 3000
            initialDelaySeconds: 15
            periodSeconds: 20
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "256Mi"
------

k8s/service.yaml


apiVersion: v1
kind: Service
metadata:
  name: hello-app
spec:
  selector:
    app: hello-app
  ports:
    - name: http
      port: 80          # cluster port
      targetPort: 3000  # container port
  type: ClusterIP

-------

k8s/ingress.yaml (using NGINX Ingress Controller)


apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hello-app
  annotations:
    kubernetes.io/ingress.class: nginx
    # Optional TLS via cert-manager:
    # cert-manager.io/cluster-issuer: letsencrypt
spec:
  tls:
    - hosts:
        - app.example.com
      secretName: hello-app-tls
  rules:
    - host: app.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: hello-app
                port:
                  number: 80
-------

# Cmds to apply the k8s manifest to cluster:


ubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml

kubectl get pods
kubectl get svc hello-app
kubectl get ingress hello-app

---------

# Routing & DNS (Kubernetes)

Your Ingress or LoadBalancer Service will get an external hostname/IP, e.g.:

abc123.elb.amazonaws.com (AWS)
a1b2c3d4.cloudapp.net (Azure)


Create DNS record pointing to that:

Route 53: A/ALIAS → target = the LB/Ingress hostname.
Cloudflare: CNAME app → target = LB hostname. (Proxy on/off)
GoDaddy: CNAME app → value = LB hostname.

# So here's what happening :

Kubernetes (cluster)
Git → Dockerfile → Image → Registry → Deployment/Service/Ingress → Cloud LB → DNS → Users
